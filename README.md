<img src="https://raw.githubusercontent.com/me-shweta/Design-Den/main/Reviews%20Scraping%20Image.png" align="center"/>

 <h2 align="center">ğŸ¬IMDB Movie review ScrappingğŸ“Š</h2>
<blockquote align="center">Scrapping the movie review âœï¸ using python programming languageğŸ’».  </blockquote>

ğŸ”Welcome to the IMDb Movie Review Scraper project! ğŸŒŸ This Python script is designed to scrape movie reviews from IMDb, providing valuable data for analysis and research purposes. The IMDb Movie Review Scraping project aims to gather a new dataset by automatically extracting movie reviews from IMDb. This dataset will support various natural language processing tasks, including sentiment analysis and recommendation systems. Using web scraping techniques, such as Beautiful Soup, movie reviews are collected, preprocessed, and structured into a CSV format suitable for analysis, including Support Vector Machine classification. ğŸ“ˆ
## Features

**`Semi-supervised-sequence-learning-Project`** : replication process is done over here and for further analysis creation of new data is required.

1. Scraping Movie Reviews ğŸ•µï¸â€â™‚ï¸
- `Movie_review_imdb_scrapping.ipynb` - The script fetches user reviews from IMDb, providing access to a diverse range of opinions and feedback for different movies. It utilizes BeautifulSoup, a powerful Python library for web scraping, to extract data from IMDb's web pages efficiently and accurately. ğŸ¥ğŸ”

2. Customizable Scraper ğŸ› ï¸
- `rename_files.ipynb` - Users can customize the scraper to target specific time periods, ratings, and other parameters, enabling focused data collection based on their requirements. This flexibility allows researchers, analysts, and enthusiasts to tailor the scraping process to their specific needs. ğŸ¯ğŸ”§

3. CSV Output ğŸ“
- `convert_texts_to_csv.ipynb` - The scraped data is saved into a CSV file, allowing for easy import into data analysis software or further processing. The CSV format ensures compatibility with a wide range of tools and platforms, making it convenient to incorporate the scraped data into various workflows and projects. ğŸ’¾ğŸ’¼



## Getting Started

**Dependencies**

Make sure you have the following dependencies installed:

* Python 3.x
* BeautifulSoup (Install using ```pip install beautifulsoup4```
* Pandas (Install using ```pip install pandas```

**Installation**

1. **Fork the `Semi-supervised-sequence-learning-Project/` repository** 
   Link to [`Semi-supervised-sequence-learning-Project'](https://github.com/sanjay-kv/Semi-supervised-sequence-learning-Project) 
   Follow these instructions on [how to fork a repository](https://help.github.com/en/articles/fork-a-repo)

2. **Clone the repository to your local machine.**
   - using SSH 
```
git clone git@github.com:your-username/Semi-supervised-sequence-learning-Project.git
```
   or
   - using HTTPS
```
https://github.com/your-username/Semi-supervised-sequence-learning-Project.git
```
3. **Navigate to the project directory.**
```
cd Semi-supervised-sequence-learning-Project
``` 
   

## Usage

**Starting the Streamlit app**

1. Navigate to the Web_app directory

```
cd Web_app
```

2. Install requirements with pip

```
pip install -r requirements.txt
```
3. Run the Streamlit app

```
streamlit run streamlit_app.py
```

**Uploading the CSV file**

When prompted by the app, upload a CSV (comma separated value) file containing the reviews.

**Demo Link**

Streamlit app link: https://scrape-review-analysis.streamlit.app

## Contribution
ğŸ‰Contributions are welcome! If you have any suggestions for improvements or new features, please feel free to submit a pull request. Your contributions help make this project better for everyone. ğŸš€
## Final Dataset

ğŸ”¬Here is the Link to **Final Dataset:** [Drive Link](https://drive.google.com/file/d/1sTNAeuy-99Hao0V5AOVznLXyDJC2zuFn/view?usp=sharing) containing the scraped IMDb movie reviews. This dataset can be used for analysis, research, or any other purposes you require. ğŸ“¦
## Support

ğŸ¤For any issues regarding the scraper, feel free to open an issue on GitHub. We'll be happy to assist you with any problems or inquiries you may have. ğŸ› ï¸
